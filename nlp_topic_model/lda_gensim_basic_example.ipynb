{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Example - Basic\n",
    "\n",
    "Reference - https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the sample documents combining together to form a corpus.\n",
    "\n",
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sugar is bad to consume. My sister likes to have sugar, but not my father.',\n",
       " 'My father spends a lot of time driving my sister around to dance practice.',\n",
       " 'Doctors suggest that driving may cause increased stress and blood pressure.',\n",
       " 'Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.',\n",
       " 'Health experts say that Sugar is not good for your lifestyle.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile documents\n",
    "\n",
    "list_doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "list_doc_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing\n",
    "\n",
    "This involves below steps:\n",
    "- Remove punctuations\n",
    "- Remove stopwords\n",
    "- Normalize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/pabhijit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sugar', 'bad', 'consume', 'sister', 'like', 'sugar', 'father'],\n",
       " ['father',\n",
       "  'spends',\n",
       "  'lot',\n",
       "  'time',\n",
       "  'driving',\n",
       "  'sister',\n",
       "  'around',\n",
       "  'dance',\n",
       "  'practice'],\n",
       " ['doctor',\n",
       "  'suggest',\n",
       "  'driving',\n",
       "  'may',\n",
       "  'cause',\n",
       "  'increased',\n",
       "  'stress',\n",
       "  'blood',\n",
       "  'pressure'],\n",
       " ['sometimes',\n",
       "  'feel',\n",
       "  'pressure',\n",
       "  'perform',\n",
       "  'well',\n",
       "  'school',\n",
       "  'father',\n",
       "  'never',\n",
       "  'seems',\n",
       "  'drive',\n",
       "  'sister',\n",
       "  'better'],\n",
       " ['health', 'expert', 'say', 'sugar', 'good', 'lifestyle']]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_doc_clean = [clean(doc).split() for doc in list_doc_complete] \n",
    "list_doc_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Document-Term Matrix\n",
    "\n",
    "- All the text documents combined is known as the corpus. \n",
    "- To run any mathematical model on text corpus, it is a good practice to convert it into a matrix representation. \n",
    "- LDA model looks for repeating term patterns in the entire DT matrix. \n",
    "- Python provides many great libraries for text mining practices, “gensim” is one such clean and beautiful library to handle text data. It is scalable, robust and efficient. Following code shows how to convert a corpus into a document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our corppus, where every unique term is assigned an index. \n",
    "dict_dictionary = corpora.Dictionary(list_doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "list_dtm = [dict_dictionary.doc2bow(doc) for doc in list_doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35 unique tokens: ['bad', 'consume', 'father', 'like', 'sister']...)\n"
     ]
    }
   ],
   "source": [
    "print(dict_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)],\n",
       " [(2, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(8, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1)],\n",
       " [(2, 1),\n",
       "  (4, 1),\n",
       "  (18, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1)],\n",
       " [(5, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA Model\n",
    "Next step is to create an object for LDA model and train it on Document-Term matrix. \n",
    "The training also requires few parameters as input which are explained in the above section. \n",
    "The gensim module allows both LDA model estimation from a training corpus and inference of topic distribution on new, unseen documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(list_dtm, num_topics=3, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.076*\"sugar\" + 0.076*\"father\" + 0.076*\"sister\"'),\n",
       " (1, '0.065*\"driving\" + 0.064*\"dance\" + 0.064*\"around\"'),\n",
       " (2, '0.050*\"pressure\" + 0.050*\"stress\" + 0.050*\"cause\"')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=3, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each line is a topic with individual topic terms and weights. \n",
    "- Topic1 can be termed as Bad Health, and Topic3 can be termed as Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
